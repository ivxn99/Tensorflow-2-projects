{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam/ham Custom Fit Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFbKxUy9mlGs"
      },
      "source": [
        "Data used for this notebook: [SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X3giMe4fyUi"
      },
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Flatten, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4vx1HAOgEaR",
        "outputId": "cb2bdfec-7c7d-4647-8909-469e598d6b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data = pd.read_csv('/content/spam.csv', encoding='latin-1')\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1  ... Unnamed: 4\n",
              "0   ham  ...        NaN\n",
              "1   ham  ...        NaN\n",
              "2  spam  ...        NaN\n",
              "3   ham  ...        NaN\n",
              "4   ham  ...        NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKrJgTJ3lxwN"
      },
      "source": [
        "We will use only label and text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3gtFUTYgI3n"
      },
      "source": [
        "data = data[['v1', 'v2']]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3h2IRVtl0Ul"
      },
      "source": [
        "Clean the text data from links, emails, symbols.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSe6p_zQgl_g",
        "outputId": "3d7dd8d0-a055-434f-f860-7234f417cfbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def get_clean_text(x):\n",
        "    x = re.sub(r'([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)', '', x) \n",
        "    #regex to remove to emails(above)\n",
        "    x = re.sub(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '', x)\n",
        "    #regex to remove URLs\n",
        "    x = re.sub('RT', \"\", x)\n",
        "    #substitute the 'RT' retweet tags with empty spaces\n",
        "    x = re.sub('[^A-Z a-z]+', '', x)\n",
        "    return x\n",
        "\n",
        "data['v2'] = data['v2'].apply(lambda x: get_clean_text(x))\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point crazy Available only in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in  a wkly comp to win FA Cup final...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor U c already then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2\n",
              "0   ham  Go until jurong point crazy Available only in ...\n",
              "1   ham                            Ok lar Joking wif u oni\n",
              "2  spam  Free entry in  a wkly comp to win FA Cup final...\n",
              "3   ham        U dun say so early hor U c already then say\n",
              "4   ham  Nah I dont think he goes to usf he lives aroun..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOa_Jlv1l66T"
      },
      "source": [
        "Manually label encode y values, and split the data into x,y train and test values. Check the shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sJWUi7Ng-nU",
        "outputId": "02586ef8-493e-4eb3-8ad0-7c762b510afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "X = data.v2\n",
        "y = data.v1.map({'ham':0, 'spam':1})\n",
        "\n",
        "train_size = int(len(data)*0.8)\n",
        "\n",
        "X_train, y_train = X[:train_size], y[:train_size]\n",
        "X_test, y_test = X[train_size:], y[train_size:]\n",
        "\n",
        "#Print the shapes\n",
        "print(\"X_train shape: \",X_train.shape)\n",
        "print(\"X_test shape: \",X_test.shape)\n",
        "print(\"y_train shape: \",y_train.shape)\n",
        "print(\"y_test shape: \",y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:  (4457,)\n",
            "X_test shape:  (1115,)\n",
            "y_train shape:  (4457,)\n",
            "y_test shape:  (1115,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1HQ5OOsmEjb"
      },
      "source": [
        "Decide on how big should the max_length be, based on average sentence length and other parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzsFB6PljDt0",
        "outputId": "629a0811-3f38-4d18-b211-9860751b74ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Max sentence length:\", X.map(len).max())\n",
        "print(\"Min sentence length:\", X.map(len).min())\n",
        "print(\"Average sentence length:\", X.map(len).mean())\n",
        "\n",
        "chars = sorted(list(set(X)))\n",
        "print('Total words:', len(chars))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length: 888\n",
            "Min sentence length: 0\n",
            "Average sentence length: 73.23869346733669\n",
            "Total words: 5119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaFYouq7mQNc"
      },
      "source": [
        "Apply tokenizer only on X_train, we cannot leak X_test words to the tokenizer.\n",
        "Create paddings for train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y89h4xlth7ym"
      },
      "source": [
        "max_length = 80\n",
        "embedding_dim = 32\n",
        "batch_size = 32\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "train_padded = pad_sequences(train_sequences, maxlen = max_length, padding='pre', truncating='pre')\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "test_padded = pad_sequences(test_sequences, maxlen = max_length, padding='pre', truncating='pre')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzz1aXWqYlFJ"
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((train_padded, y_train))\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test_padded, y_test))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpqPQ25VtKG7",
        "outputId": "2b9dd3b0-f6aa-4266-b3bc-fadebb5c7446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model = Sequential([\n",
        "                    Embedding(len(word_index)+1, embedding_dim, input_length=max_length),\n",
        "                    LSTM(50),\n",
        "                    Dense(32, activation='relu'),\n",
        "                    Dense(1)\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 80, 32)            243104    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                16600     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1632      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 261,369\n",
            "Trainable params: 261,369\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YETWPcvYtftT",
        "outputId": "2bc16b3a-7673-4aa6-87e3-7e8185d68497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "class CustomFit(tf.keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super(CustomFit, self).__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def compile(self, optimizer, loss):\n",
        "    super(CustomFit, self).compile()\n",
        "    self.optimizer=optimizer\n",
        "    self.loss = loss\n",
        "\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self.model(x, training=True)\n",
        "      loss = self.loss(y, y_pred)\n",
        "\n",
        "    training_vars = self.trainable_variables\n",
        "    gradients = tape.gradient(loss, training_vars)\n",
        "\n",
        "    self.optimizer.apply_gradients(zip(gradients, training_vars))\n",
        "    acc_metric.update_state(y, y_pred)\n",
        "\n",
        "    return {\"loss\": loss, \"accuracy\": acc_metric.result()}\n",
        "  \n",
        "  def test_step(self, data):\n",
        "    x, y = data\n",
        "    y_pred = self.model(x, training=False)\n",
        "    loss = self.loss(y, y_pred)\n",
        "    acc_metric.update_state(y, y_pred)\n",
        "\n",
        "    return{\"loss\":loss, \"accuracy\":acc_metric.result()}\n",
        "\n",
        "acc_metric = tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
        "\n",
        "training = CustomFit(model)\n",
        "training.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
        "training.fit(train_padded, y_train, batch_size=batch_size, epochs=20)\n",
        "training.evaluate(test_padded, y_test, batch_size=batch_size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "140/140 [==============================] - 6s 41ms/step - loss: 0.2422 - accuracy: 0.8834\n",
            "Epoch 2/20\n",
            "140/140 [==============================] - 6s 43ms/step - loss: 0.0413 - accuracy: 0.9293\n",
            "Epoch 3/20\n",
            "140/140 [==============================] - 7s 47ms/step - loss: 0.0178 - accuracy: 0.9555\n",
            "Epoch 4/20\n",
            "140/140 [==============================] - 6s 46ms/step - loss: 0.0088 - accuracy: 0.9674\n",
            "Epoch 5/20\n",
            "140/140 [==============================] - 6s 45ms/step - loss: 0.0057 - accuracy: 0.9744\n",
            "Epoch 6/20\n",
            "140/140 [==============================] - 6s 42ms/step - loss: 0.0026 - accuracy: 0.9789\n",
            "Epoch 7/20\n",
            "140/140 [==============================] - 6s 42ms/step - loss: 0.0018 - accuracy: 0.9820\n",
            "Epoch 8/20\n",
            "140/140 [==============================] - 6s 43ms/step - loss: 7.4165e-04 - accuracy: 0.9844\n",
            "Epoch 9/20\n",
            "140/140 [==============================] - 6s 43ms/step - loss: 3.1193e-04 - accuracy: 0.9862\n",
            "Epoch 10/20\n",
            "140/140 [==============================] - 6s 43ms/step - loss: 1.7355e-04 - accuracy: 0.9876\n",
            "Epoch 11/20\n",
            "140/140 [==============================] - 6s 42ms/step - loss: 1.2475e-04 - accuracy: 0.9888\n",
            "Epoch 12/20\n",
            "140/140 [==============================] - 6s 43ms/step - loss: 9.8697e-05 - accuracy: 0.9898\n",
            "Epoch 13/20\n",
            "140/140 [==============================] - 7s 47ms/step - loss: 6.6687e-05 - accuracy: 0.9906\n",
            "Epoch 14/20\n",
            "140/140 [==============================] - 6s 44ms/step - loss: 4.9835e-05 - accuracy: 0.9913\n",
            "Epoch 15/20\n",
            "140/140 [==============================] - 6s 43ms/step - loss: 3.9727e-05 - accuracy: 0.9919\n",
            "Epoch 16/20\n",
            "140/140 [==============================] - 6s 43ms/step - loss: 3.1820e-05 - accuracy: 0.9924\n",
            "Epoch 17/20\n",
            "140/140 [==============================] - 6s 43ms/step - loss: 2.7752e-05 - accuracy: 0.9929\n",
            "Epoch 18/20\n",
            "140/140 [==============================] - 6s 45ms/step - loss: 2.2179e-05 - accuracy: 0.9933\n",
            "Epoch 19/20\n",
            "140/140 [==============================] - 6s 44ms/step - loss: 1.8495e-05 - accuracy: 0.9937\n",
            "Epoch 20/20\n",
            "140/140 [==============================] - 6s 44ms/step - loss: 1.6156e-05 - accuracy: 0.9940\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1059 - accuracy: 0.9941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}